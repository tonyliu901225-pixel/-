import streamlit as st
import requests
import pandas as pd
import io

# --- é¡µé¢é…ç½® ---
st.set_page_config(page_title="å°çº¢ä¹¦AI (V23 æœ€ç»ˆæ™ºèƒ½ç‰ˆ)", page_icon="ğŸ’", layout="wide")

# å¼ºåˆ¶å®˜æ–¹åœ°å€
BASE_URL = "https://generativelanguage.googleapis.com"

# --- æ ¸å¿ƒï¼šè‡ªåŠ¨æŒ‘é€‰â€œä¼šè¯´è¯â€çš„æ¨¡å‹ ---
def get_best_model(api_key):
    # 1. é—® Googleï¼šæˆ‘æœ‰é‚£äº›æ¨¡å‹ï¼Ÿ
    url = f"{BASE_URL}/v1beta/models?key={api_key}"
    try:
        resp = requests.get(url, timeout=10)
        if resp.status_code != 200:
            return None, f"è·å–æ¨¡å‹å¤±è´¥: {resp.status_code}"
            
        data = resp.json()
        models = data.get('models', [])
        
        # 2. ç­›é€‰ï¼šåªæ‰¾æ”¯æŒ 'generateContent' çš„æ¨¡å‹
        chat_models = []
        for m in models:
            if 'generateContent' in m.get('supportedGenerationMethods', []):
                name = m['name'].replace('models/', '')
                chat_models.append(name)
        
        if not chat_models:
            return None, "æ‚¨çš„ Key æœ‰æ•ˆï¼Œä½†æ²¡æ‰¾åˆ°æ”¯æŒå¯¹è¯çš„æ¨¡å‹ã€‚"
            
        # 3. ä¼˜é€‰ï¼šä¼˜å…ˆæ‰¾ flash æˆ– proï¼Œæ‰¾ä¸åˆ°å°±ç”¨ç¬¬ä¸€ä¸ª
        best_model = chat_models[0] # é»˜è®¤ç¬¬ä¸€ä¸ª
        for m in chat_models:
            if "flash" in m: 
                best_model = m; break
            elif "pro" in m and "vision" not in m: # é¿å¼€çº¯è§†è§‰æ¨¡å‹
                best_model = m
                
        return best_model, None

    except Exception as e:
        return None, f"ç½‘ç»œé”™è¯¯: {e}"

# --- AI è°ƒç”¨ ---
def call_gemini(prompt, api_key, model_name):
    url = f"{BASE_URL}/v1beta/models/{model_name}:generateContent?key={api_key}"
    headers = {'Content-Type': 'application/json'}
    payload = {"contents": [{"parts": [{"text": prompt}]}]}
    
    try:
        response = requests.post(url, headers=headers, json=payload, timeout=30)
        if response.status_code == 200:
            return True, response.json()['candidates'][0]['content']['parts'][0]['text']
        else:
            return False, f"APIæŠ¥é”™: {response.text}"
    except Exception as e:
        return False, f"ç½‘ç»œé”™è¯¯: {e}"

# --- ä¸»ç•Œé¢ ---
st.title("ğŸ’ å°çº¢ä¹¦ AI é€‰é¢˜ä¸­å°")
st.caption("ğŸš€ V23.0 æ™ºèƒ½è¿‡æ»¤ç‰ˆ | å·²è§£å†³ embedding æ¨¡å‹æŠ¥é”™é—®é¢˜")

# åˆå§‹åŒ– Session State
if 'working_model' not in st.session_state:
    st.session_state.working_model = None

with st.sidebar:
    st.header("ğŸ”‘ è®¾ç½®")
    api_key = st.text_input("è¾“å…¥ API Key", type="password")
    
    # è‡ªåŠ¨åˆå§‹åŒ–æ¨¡å‹
    if api_key and not st.session_state.working_model:
        model, err = get_best_model(api_key)
        if model:
            st.session_state.working_model = model
            st.success(f"âœ… å·²é”å®šæ¨¡å‹: {model}")
        else:
            if err: st.error(err)
    
    # å¦‚æœå·²ç»é”å®šäº†æ¨¡å‹ï¼Œæ˜¾ç¤ºå‡ºæ¥
    if st.session_state.working_model:
        st.info(f"å½“å‰ä½¿ç”¨: {st.session_state.working_model}")

    uploaded_file = st.file_uploader("ğŸ“‚ ä¸Šä¼  Excel", type=['xlsx', 'csv'])

# ä¸»å·¥ä½œåŒº
col1, col2 = st.columns([1, 2])
with col1:
    txt = st.text_area("æ–‡æ¡ˆè¾“å…¥", height=300)
    
    can_run = api_key and st.session_state.working_model
    
    if st.button("âœ¨ å¼€å§‹æ‰§è¡Œ", type="primary", use_container_width=True, disabled=not can_run):
        if not txt and not uploaded_file: st.warning("è¯·è¾“å…¥å†…å®¹"); st.stop()
        
        tasks = []
        if txt: tasks.extend([t.strip() for t in txt.split('\n\n') if len(t.strip())>5])
        if uploaded_file:
            try:
                df = pd.read_csv(uploaded_file) if uploaded_file.name.endswith('.csv') else pd.read_excel(uploaded_file)
                tasks.extend(df.iloc[:,0].dropna().astype(str).tolist())
            except: pass
            
        bar = st.progress(0); log = st.empty(); res = []
        model_used = st.session_state.working_model
        
        for i, t in enumerate(tasks):
            log.text(f"å¤„ç†ç¬¬ {i+1} æ¡...")
            
            # 1. åˆ†æ
            p1 = f"åˆ†ææ–‡æ¡ˆ:'{t[:500]}'.æå–:åŸæ ‡é¢˜|||äººè®¾|||é€‰é¢˜|||å…¬å¼"
            ok, r1 = call_gemini(p1, api_key, model_used)
            item = {"åŸæ–‡": t[:15], "ç»“æœ": ""}
            
            if ok and "|||" in r1:
                parts = r1.split("|||")
                if len(parts)>=4:
                    # 2. ç”Ÿæˆ
                    p2 = f"æˆ‘æ˜¯{parts[1]},å†™5ä¸ªå…³äº{parts[2]}çš„æ ‡é¢˜"
                    ok2, r2 = call_gemini(p2, api_key, model_used)
                    item["ç»“æœ"] = r2 if ok2 else r2
                else: item["ç»“æœ"] = r1
            else: item["ç»“æœ"] = r1
            
            res.append(item)
            bar.progress((i+1)/len(tasks))
            
        st.session_state.results = res
        log.success("å®Œæˆï¼")

with col2:
    if 'results' in st.session_state and st.session_state.results:
        st.dataframe(pd.DataFrame(st.session_state.results), use_container_width=True)
