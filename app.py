import streamlit as st
import requests
import pandas as pd
import io
import time
import base64

# ==========================================
# 1. åŸºç¡€é…ç½®
# ==========================================
st.set_page_config(
    page_title="å°çº¢ä¹¦ AI é€‰é¢˜ä¸­å° (V26 è§†è§‰å…¨èƒ½ç‰ˆ)",
    page_icon="ğŸ’",
    layout="wide",
    initial_sidebar_state="expanded"
)

BASE_URL = "https://generativelanguage.googleapis.com"

# é»˜è®¤çš„æ ‡é¢˜ç”Ÿæˆé£æ ¼ (ç”¨æˆ·å¯ä¿®æ”¹)
DEFAULT_STYLE_PROMPT = """
1. **æ¯ä¸ªæ ‡é¢˜å¿…é¡»æ§åˆ¶åœ¨ 20 å­—ä»¥å†…** (éå¸¸é‡è¦)ã€‚
2. åˆ† 5 è¡Œå±•ç¤ºï¼Œæ¯è¡Œä¸€ä¸ªã€‚
3. ä¸è¦åŠ åºå· (å¦‚ 1. 2.)ï¼Œä¸è¦åŠ å¼•å·ã€‚
4. å£è¯­åŒ–ï¼Œå¸¦æƒ…ç»ªï¼ŒåŠ å…¥emojiã€‚
5. é’ˆå¯¹å•†åŠ¡/èŒåœº/é€ç¤¼åœºæ™¯ã€‚
"""

# ==========================================
# 2. æ ¸å¿ƒå‡½æ•° (æ”¯æŒå›¾ç‰‡)
# ==========================================

def get_best_model(api_key):
    """æ™ºèƒ½æ¨¡å‹ç­›é€‰å™¨ (è‡ªåŠ¨é”å®šæ”¯æŒè§†è§‰çš„ flash æ¨¡å‹)"""
    url = f"{BASE_URL}/v1beta/models?key={api_key}"
    try:
        resp = requests.get(url, timeout=10)
        if resp.status_code != 200:
            return None, f"Key éªŒè¯å¤±è´¥ ({resp.status_code})"
            
        data = resp.json()
        models = data.get('models', [])
        
        # ç­›é€‰æ”¯æŒç”Ÿæˆå†…å®¹çš„æ¨¡å‹
        chat_models = []
        for m in models:
            if 'generateContent' in m.get('supportedGenerationMethods', []):
                name = m['name'].replace('models/', '')
                chat_models.append(name)
        
        if not chat_models:
            return None, "æœªæ‰¾åˆ°å¯ç”¨æ¨¡å‹ã€‚"
            
        # ä¼˜é€‰ Flash (é€Ÿåº¦å¿«ä¸”è§†è§‰èƒ½åŠ›å¼º)
        best_model = chat_models[0]
        for m in chat_models:
            if "flash" in m: 
                best_model = m; break
            elif "pro" in m and "vision" not in m:
                best_model = m
                
        return best_model, None

    except Exception as e:
        return None, f"ç½‘ç»œé”™è¯¯: {e}"

def call_gemini(prompt, api_key, model_name, image_data=None):
    """
    é€šç”¨ AI è°ƒç”¨ (æ”¯æŒçº¯æ–‡æœ¬ æˆ– æ–‡æœ¬+å›¾ç‰‡)
    image_data: {'mime_type': 'image/png', 'data': 'base64_string...'}
    """
    url = f"{BASE_URL}/v1beta/models/{model_name}:generateContent?key={api_key}"
    headers = {'Content-Type': 'application/json'}
    
    # æ„å»ºè¯·æ±‚ä½“
    parts = [{"text": prompt}]
    
    # å¦‚æœæœ‰å›¾ç‰‡ï¼ŒåŠ å…¥å›¾ç‰‡æ•°æ®
    if image_data:
        parts.append({
            "inline_data": {
                "mime_type": image_data['mime_type'],
                "data": image_data['data']
            }
        })
        
    payload = {"contents": [{"parts": parts}]}
    
    try:
        response = requests.post(url, headers=headers, json=payload, timeout=60) # å›¾ç‰‡å¤„ç†ç¨æ…¢ï¼Œç»™60ç§’
        if response.status_code == 200:
            return True, response.json()['candidates'][0]['content']['parts'][0]['text']
        else:
            return False, f"APIæŠ¥é”™ {response.status_code}: {response.text[:200]}"
    except Exception as e:
        return False, f"ç½‘ç»œé”™è¯¯: {str(e)}"

# ==========================================
# 3. ç•Œé¢é€»è¾‘
# ==========================================

if 'results' not in st.session_state:
    st.session_state.results = []
if 'working_model' not in st.session_state:
    st.session_state.working_model = None

# --- ä¾§è¾¹æ  ---
with st.sidebar:
    st.image("https://upload.wikimedia.org/wikipedia/commons/thumb/d/d0/Xiaohongshu_logo.svg/1200px-Xiaohongshu_logo.svg.png", width=50)
    st.header("âš™ï¸ å…¨å±€è®¾ç½®")
    
    api_key = st.text_input("è¾“å…¥ API Key", type="password", help="è¯·ç”¨å¸¦ç»¿å‹¾çš„ Key")
    
    # æ¨¡å‹æ£€æµ‹
    if api_key and not st.session_state.working_model:
        with st.spinner("æ­£åœ¨è¿æ¥ Google è§†è§‰å¤§è„‘..."):
            model, err = get_best_model(api_key)
            if model:
                st.session_state.working_model = model
                st.success(f"âœ… è§†è§‰æ¨¡å‹å°±ç»ª: {model}")
            else:
                st.error(f"âŒ {err}")
    
    st.divider()
    
    # --- æ–°åŠŸèƒ½ 1: æç¤ºè¯é¢„è®¾ ---
    st.subheader("ğŸ¨ é£æ ¼è°ƒä¼˜ (Prompt)")
    with st.expander("ç‚¹å‡»ä¿®æ”¹æ ‡é¢˜ç”Ÿæˆè¦æ±‚", expanded=False):
        user_style_prompt = st.text_area(
            "åœ¨æ­¤è°ƒæ•´è¾“å‡ºé£æ ¼/å­—æ•°/è¯­æ°”ï¼š", 
            value=DEFAULT_STYLE_PROMPT,
            height=150
        )
    
    st.divider()
    # --- æ–°åŠŸèƒ½ 2: æ”¯æŒå›¾ç‰‡ä¸Šä¼  ---
    uploaded_file = st.file_uploader(
        "ğŸ“‚ ä¸Šä¼ ç´ æ (Excel/å›¾ç‰‡)", 
        type=['xlsx', 'csv', 'png', 'jpg', 'jpeg'],
        accept_multiple_files=False
    )
    st.caption("æ”¯æŒï¼šExcelè¡¨æ ¼ æˆ– ç¬”è®°æˆªå›¾/äº§å“å®æ‹å›¾")

# --- ä¸»ç•Œé¢ ---
st.title("ğŸ’ å°çº¢ä¹¦ AI é€‰é¢˜ä¸­å°")
st.caption("ğŸš€ V26.0 è§†è§‰å…¨èƒ½ç‰ˆ | æ”¯æŒå›¾ç‰‡è¯†åˆ« | è‡ªå®šä¹‰é£æ ¼")

col1, col2 = st.columns([1, 1.5])

# å·¦ä¾§ï¼šè¾“å…¥
with col1:
    st.subheader("ğŸ“ è¾“å…¥ç´ æ")
    txt_input = st.text_area("ç²˜è´´æ–‡æ¡ˆ (çº¯æ–‡æœ¬æ¨¡å¼)", height=200, placeholder="åœ¨æ­¤ç²˜è´´ç«å“æ–‡æ¡ˆ...")
    
    can_run = api_key and st.session_state.working_model
    
    if st.button("âœ¨ å¼€å§‹æ™ºèƒ½ç”Ÿæˆ", type="primary", use_container_width=True, disabled=not can_run):
        
        # 1. ç»Ÿä¸€æ„å»ºä»»åŠ¡åˆ—è¡¨
        # ä»»åŠ¡ç»“æ„: {'type': 'text'/'image', 'content': ..., 'name': ...}
        tasks = []
        
        # A. å¤„ç†æ–‡æœ¬æ¡†è¾“å…¥
        if txt_input:
            texts = [t.strip() for t in txt_input.split('\n\n') if len(t.strip()) > 5]
            for t in texts:
                tasks.append({'type': 'text', 'content': t, 'name': t[:10]})
                
        # B. å¤„ç†ä¸Šä¼ æ–‡ä»¶ (Excel æˆ– å›¾ç‰‡)
        if uploaded_file:
            file_type = uploaded_file.name.split('.')[-1].lower()
            
            # å¦‚æœæ˜¯ Excel/CSV -> è¯»æ–‡å­—
            if file_type in ['xlsx', 'csv']:
                try:
                    df = pd.read_csv(uploaded_file) if file_type == 'csv' else pd.read_excel(uploaded_file)
                    file_texts = df.iloc[:, 0].dropna().astype(str).tolist()
                    for t in file_texts:
                        tasks.append({'type': 'text', 'content': t, 'name': str(t)[:10]})
                except: st.error("è¡¨æ ¼è¯»å–å¤±è´¥")
            
            # å¦‚æœæ˜¯ å›¾ç‰‡ -> è¯»äºŒè¿›åˆ¶
            elif file_type in ['png', 'jpg', 'jpeg']:
                try:
                    # è¯»å–å›¾ç‰‡å­—èŠ‚å¹¶è½¬ Base64
                    bytes_data = uploaded_file.getvalue()
                    base64_str = base64.b64encode(bytes_data).decode('utf-8')
                    mime_type = f"image/{file_type if file_type != 'jpg' else 'jpeg'}"
                    
                    tasks.append({
                        'type': 'image', 
                        'content': {'mime_type': mime_type, 'data': base64_str},
                        'name': f"å›¾ç‰‡: {uploaded_file.name}"
                    })
                except: st.error("å›¾ç‰‡å¤„ç†å¤±è´¥")

        if not tasks: st.warning("è¯·å…ˆè¾“å…¥å†…å®¹æˆ–ä¸Šä¼ æ–‡ä»¶"); st.stop()
            
        # 2. å¼€å§‹æ‰§è¡Œ
        progress_bar = st.progress(0)
        status_text = st.empty()
        new_results = []
        model_used = st.session_state.working_model
        
        for i, task in enumerate(tasks):
            status_text.markdown(f"ğŸ”„ **æ­£åœ¨åˆ†æç¬¬ {i+1}/{len(tasks)} æ¡...**")
            
            # --- Step 1: æ‹†è§£ (åŒºåˆ†æ–‡æœ¬å’Œå›¾ç‰‡) ---
            
            if task['type'] == 'text':
                prompt_analyze = f"""
                åˆ†ææ–‡æ¡ˆ:"{task['content'][:800]}..."
                è¯·æå–ä»¥ä¸‹4é¡¹ï¼Œä¸¥æ ¼ç”¨ '|||' éš”å¼€ï¼š
                1. åŸæ ‡é¢˜
                2. äººè®¾ (é”€å”®è€å¾ / æ€»åŠ©Fiona / å…¶ä»–)
                3. æ ¸å¿ƒé€‰é¢˜ (âš ï¸è¦æ±‚ï¼šåˆ‡å…¥ç‚¹è¦æç»†ï¼å¿…é¡»åŒ…å«å…·ä½“åœºæ™¯æˆ–å…·ä½“ç—›ç‚¹)
                4. çˆ†æ¬¾å…¬å¼
                """
                img_data = None
            else:
                # å›¾ç‰‡æ¨¡å¼
                prompt_analyze = f"""
                è¯·ä»”ç»†çœ‹è¿™å¼ å›¾ç‰‡ã€‚
                æå–å¹¶åˆ†æä»¥ä¸‹4é¡¹ä¿¡æ¯ï¼Œä¸¥æ ¼ç”¨ '|||' éš”å¼€ï¼š
                1. å›¾ç‰‡ä¸­çš„æ ¸å¿ƒæ–‡æ¡ˆæˆ–ä¸»é¢˜ (ä½œä¸ºåŸæ ‡é¢˜)
                2. æ¨æµ‹å‘å¸–äººè®¾ (é”€å”®è€å¾ / æ€»åŠ©Fiona / å…¶ä»–)
                3. æ ¸å¿ƒé€‰é¢˜ (âš ï¸è¦æ±‚ï¼šæ ¹æ®å›¾ç‰‡å†…å®¹æç‚¼æç»†çš„ç—›ç‚¹æˆ–åœºæ™¯)
                4. é€‚åˆè¿™å¼ å›¾çš„çˆ†æ¬¾æ ‡é¢˜å…¬å¼
                """
                img_data = task['content']

            # è°ƒç”¨ AI (åˆ†æ)
            ok1, res1 = call_gemini(prompt_analyze, api_key, model_used, image_data=img_data)
            
            item = {
                "æ¥æº": task['name'],
                "äººè®¾": "æœªçŸ¥",
                "é€‰é¢˜": "è§£æå¤±è´¥",
                "ç”Ÿæˆæ ‡é¢˜": ""
            }
            
            if ok1 and "|||" in res1:
                parts = res1.replace('```', '').strip().split('|||')
                if len(parts) >= 4:
                    item["äººè®¾"] = parts[1].strip()
                    item["é€‰é¢˜"] = parts[2].strip()
                    formula = parts[3].strip()
                    
                    # --- Step 2: ç”Ÿæˆ (ä½¿ç”¨ç”¨æˆ·è‡ªå®šä¹‰çš„ Style Prompt) ---
                    prompt_gen = f"""
                    ä½ ç°åœ¨æ˜¯å°çº¢ä¹¦åšä¸»ã€{item['äººè®¾']}ã€‘ã€‚
                    é’ˆå¯¹ç»†åˆ†é€‰é¢˜ï¼š"{item['é€‰é¢˜']}"ã€‚
                    å‚è€ƒå…¬å¼ï¼š"{formula}"ã€‚
                    
                    ğŸ‘‰ è¯·å†™ 5 ä¸ªæ ‡é¢˜ã€‚
                    âš ï¸ ä¸¥æ ¼éµå®ˆä»¥ä¸‹é£æ ¼è¦æ±‚ï¼š
                    {user_style_prompt}
                    """
                    # ç”Ÿæˆæ­¥éª¤ä¸éœ€è¦å›¾ç‰‡ï¼Œåªéœ€è¦æ–‡å­—é€»è¾‘
                    ok2, res2 = call_gemini(prompt_gen, api_key, model_used)
                    item["ç”Ÿæˆæ ‡é¢˜"] = res2 if ok2 else "ç”Ÿæˆå¤±è´¥"
                else:
                    item["ç”Ÿæˆæ ‡é¢˜"] = res1
            else:
                item["ç”Ÿæˆæ ‡é¢˜"] = res1
            
            new_results.append(item)
            progress_bar.progress((i + 1) / len(tasks))
            
        st.session_state.results = new_results + st.session_state.results
        status_text.success("ğŸ‰ å®Œæˆï¼")

# å³ä¾§ï¼šç»“æœ
with col2:
    st.subheader(f"ğŸ“Š ç»“æœ ({len(st.session_state.results)})")
    
    if st.session_state.results:
        df_res = pd.DataFrame(st.session_state.results)
        
        st.dataframe(
            df_res, 
            column_config={
                "ç”Ÿæˆæ ‡é¢˜": st.column_config.TextColumn("AI çˆ†æ¬¾æ ‡é¢˜", width="large", help="è‡ªåŠ¨æ¢è¡Œ"),
                "é€‰é¢˜": st.column_config.TextColumn("ç»†åˆ†åˆ‡å…¥ç‚¹", width="medium"),
                "æ¥æº": st.column_config.TextColumn("æ¥æº", width="small"),
            },
            use_container_width=True,
            height=600
        )
        
        # Excel å¯¼å‡ºé…ç½®
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            df_res.to_excel(writer, index=False, sheet_name='Sheet1')
            workbook = writer.book
            worksheet = writer.sheets['Sheet1']
            wrap_format = workbook.add_format({'text_wrap': True, 'valign': 'top'})
            worksheet.set_column('A:A', 15)
            worksheet.set_column('B:B', 15)
            worksheet.set_column('C:C', 30, wrap_format)
            worksheet.set_column('D:D', 50, wrap_format)
            
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½ Excel",
            data=output.getvalue(),
            file_name=f"å°çº¢ä¹¦AI_{int(time.time())}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True
        )
        
        if st.button("ğŸ—‘ï¸ æ¸…ç©º"):
            st.session_state.results = []
            st.rerun()
